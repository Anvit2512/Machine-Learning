{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c178b4-622f-4d3f-b5c7-2ecfb172d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'AWCustomers.csv'\n",
    "\n",
    "df_customers= pd.read_csv(file_path)\n",
    "df_sales=pd.read_csv('AWSales.csv')\n",
    "df_test_C=pd.read_csv('AWTest-Classification.csv')\n",
    "df_test_R=pd.read_csv('AWTest-Regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39c7251-0391-4e03-9243-87fc2e1118cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file 'filtered.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "df_customers['Age'] = pd.to_datetime('today').year - pd.to_datetime(df_customers['BirthDate']).dt.year\n",
    "columns_to_select = ['CustomerID','City', 'StateProvinceName', 'Age', 'Education', 'Occupation', 'Gender', \n",
    "                  'MaritalStatus', 'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome', \n",
    "                  'YearlyIncome']\n",
    "selected_df = df_customers[columns_to_select]\n",
    "output_file_path = 'filtered.csv'\n",
    "selected_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"New file '{output_file_path}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b873580e-a70c-4695-85c2-987f9e120184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows removed and the cleaned file 'filtered.csv' has been saved.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'filtered.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_cleaned = df.drop_duplicates()\n",
    "df_cleaned.to_csv(file_path, index=False)\n",
    "print(f\"Duplicate rows removed and the cleaned file '{file_path}' has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9568fdab-fed1-4222-bd30-6699e5267263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows removed and the cleaned file 'AWSales.csv' has been saved.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'AWSales.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_cleaned = df.drop_duplicates()\n",
    "df_cleaned.to_csv(file_path, index=False)\n",
    "print(f\"Duplicate rows removed and the cleaned file '{file_path}' has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07aa8914-3b31-483c-8e5f-8447a12a50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved to 'combined_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "filtered_df = pd.read_csv('filtered.csv')\n",
    "AWSales_df = pd.read_csv('AWSales.csv')\n",
    "\n",
    "combined_df = pd.merge(filtered_df, AWSales_df, on='CustomerID')\n",
    "\n",
    "combined_df.to_csv('combined_output.csv', index=False)\n",
    "\n",
    "print(\"Combined DataFrame saved to 'combined_output.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93b78aa-21bf-44fe-9877-2de0a1f40d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID has no null values.\n",
      "All CustomerID values are integers.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('combined_output.csv')\n",
    "null_values = df['CustomerID'].isnull().sum()\n",
    "\n",
    "integer_check = pd.to_numeric(df['CustomerID'], errors='coerce').notna().all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"CustomerID has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"CustomerID has no null values.\")\n",
    "\n",
    "if integer_check:\n",
    "    print(\"All CustomerID values are integers.\")\n",
    "else:\n",
    "    print(\"Some CustomerID values are not integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fce4d177-f34c-4f97-a808-d35733f32aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City has no null values.\n",
      "All City values are strings.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['City'].isnull().sum()\n",
    "string_check = df['City'].apply(lambda x: isinstance(x, str)).all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"City has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"City has no null values.\")\n",
    "\n",
    "if string_check:\n",
    "    print(\"All City values are strings.\")\n",
    "else:\n",
    "    print(\"Some City values are not strings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7eafa7-0042-4e0f-bf84-af6b79cc1d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateProvinceName has no null values.\n",
      "All StateProvinceName values are strings.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['StateProvinceName'].isnull().sum()\n",
    "string_check = df['StateProvinceName'].apply(lambda x: isinstance(x, str)).all()\n",
    "if null_values > 0:\n",
    "    print(f\"StateProvinceName has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"StateProvinceName has no null values.\")\n",
    "\n",
    "if string_check:\n",
    "    print(\"All StateProvinceName values are strings.\")\n",
    "else:\n",
    "    print(\"Some StateProvinceName values are not strings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c365f6b1-c126-449d-911f-da1b8e46bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age has no null values.\n",
      "All Age values are integers.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['Age'].isnull().sum()\n",
    "integer_check = pd.to_numeric(df['Age'], errors='coerce').apply(lambda x: x.is_integer()).all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"Age has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"Age has no null values.\")\n",
    "\n",
    "if integer_check:\n",
    "    print(\"All Age values are integers.\")\n",
    "else:\n",
    "    print(\"Some Age values are not integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9220b7f-3bab-44b3-a022-893e01a730eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education has no null values.\n",
      "All Education values are strings.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['Education'].isnull().sum()\n",
    "string_check = df['Education'].apply(lambda x: isinstance(x, str)).all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"Education has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"Education has no null values.\")\n",
    "\n",
    "if string_check:\n",
    "    print(\"All Education values are strings.\")\n",
    "else:\n",
    "    print(\"Some Education values are not strings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc1b72a-bc64-4ab8-a7ae-2c28108f2570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender has no null values.\n",
      "All Gender values are either 'M' or 'F'.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['Gender'].isnull().sum()\n",
    "\n",
    "valid_values = df['Gender'].apply(lambda x: x in ['M', 'F']).all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"Gender has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"Gender has no null values.\")\n",
    "\n",
    "if valid_values:\n",
    "    print(\"All Gender values are either 'M' or 'F'.\")\n",
    "else:\n",
    "    print(\"Some Gender values are not 'M' or 'F'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "363512a2-c304-4eb6-b1b4-68e22f92cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaritalStatus has no null values.\n",
      "All MaritalStatus values are either 'M' or 'S'.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['MaritalStatus'].isnull().sum()\n",
    "\n",
    "valid_values = df['MaritalStatus'].apply(lambda x: x in ['M', 'S']).all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"MaritalStatus has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"MaritalStatus has no null values.\")\n",
    "\n",
    "if valid_values:\n",
    "    print(\"All MaritalStatus values are either 'M' or 'S'.\")\n",
    "else:\n",
    "    print(\"Some MaritalStatus values are not 'M' or 'S'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f1be921-1f1c-488b-b210-e74819c9ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomeOwnerFlag has no null values.\n",
      "All HomeOwnerFlag values are integers.\n",
      "\n",
      "\n",
      "NumberCarsOwned has no null values.\n",
      "All NumberCarsOwned values are integers.\n",
      "\n",
      "\n",
      "NumberChildrenAtHome has no null values.\n",
      "All NumberChildrenAtHome values are integers.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_column(column_name):\n",
    "    null_values = df[column_name].isnull().sum()\n",
    "    integer_check = pd.to_numeric(df[column_name], errors='coerce').apply(lambda x: x.is_integer()).all()\n",
    "    if null_values > 0:\n",
    "        print(f\"{column_name} has {null_values} null values.\")\n",
    "    else:\n",
    "        print(f\"{column_name} has no null values.\")\n",
    "    \n",
    "    if integer_check:\n",
    "        print(f\"All {column_name} values are integers.\")\n",
    "    else:\n",
    "        print(f\"Some {column_name} values are not integers.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "check_column('HomeOwnerFlag')\n",
    "check_column('NumberCarsOwned')\n",
    "check_column('NumberChildrenAtHome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b81e1ab4-47e7-4fc2-b43f-59ea43609f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearlyIncome has no null values.\n",
      "All YearlyIncome values are integers.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_column('YearlyIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b64a2cf-e9f0-4ad1-b921-0e044da089f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BikeBuyer has no null values.\n",
      "All BikeBuyer values are integers.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_column('BikeBuyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09fb220a-105f-42d3-9360-526fdb59d39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgMonthSpend has no null values.\n",
      "All AvgMonthSpend values are floats.\n"
     ]
    }
   ],
   "source": [
    "null_values = df['AvgMonthSpend'].isnull().sum()\n",
    "\n",
    "float_check = pd.to_numeric(df['AvgMonthSpend'], errors='coerce').apply(lambda x: isinstance(x, float)).all()\n",
    "\n",
    "if null_values > 0:\n",
    "    print(f\"AvgMonthSpend has {null_values} null values.\")\n",
    "else:\n",
    "    print(\"AvgMonthSpend has no null values.\")\n",
    "\n",
    "if float_check:\n",
    "    print(\"All AvgMonthSpend values are floats.\")\n",
    "else:\n",
    "    print(\"Some AvgMonthSpend values are not floats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ad0b514-d309-4cb7-bac0-083475fef74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_output.csv')\n",
    "df.to_csv('new_combined_output.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f23e941a-867a-4d4e-a537-7c739c29903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_combined_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "634176a5-3726-4e47-b89d-8b34ea90faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['City', 'StateProvinceName', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag']\n",
    "for column in columns_to_encode:\n",
    "    df[column] = df[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "759008ec-6b17-418e-b6d4-6a1aeb222d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8aa1cbd6-2daf-405a-82da-334f7f99bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_combined_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51085795-2d4d-402c-9eb2-8b3d9ca33f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "columns_to_encode = ['City', 'StateProvinceName', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag']\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f560f356-e6c7-440a-a995-03a8eb2bf95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('label_encoded_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "324353bf-646e-4d03-8e10-0fca7a11811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('new_combined_output.csv') \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "columns_to_encode = ['City', 'StateProvinceName', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag']\n",
    "\n",
    "category_mappings = pd.DataFrame()\n",
    "\n",
    "for column in columns_to_encode:\n",
    "   \n",
    "    df[column] = le.fit_transform(df[column])\n",
    "   \n",
    "    mapping_df = pd.DataFrame({\n",
    "        'Category': le.classes_,\n",
    "        'Label': le.transform(le.classes_)\n",
    "    })\n",
    "    \n",
    "    mapping_df['Column'] = column\n",
    "    \n",
    "    category_mappings = pd.concat([category_mappings, mapping_df], ignore_index=True)\n",
    "\n",
    "category_mappings.to_csv('category_mappings.csv', index=False)\n",
    "\n",
    "df.to_csv('label_encoded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af61a584-43ee-4e64-84bb-152cbba7863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Education' column:\n",
      "Bachelors\n",
      "Partial College\n",
      "High School\n",
      "Partial High School\n",
      "Graduate Degree\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('label_encoded_data.csv')\n",
    "\n",
    "unique_education_values = df['Education'].unique()\n",
    "\n",
    "print(\"Unique values in 'Education' column:\")\n",
    "for value in unique_education_values:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea83f835-dcaf-4484-a73f-cc1068625a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Education  Education_encoded\n",
      "0            Bachelors                3.0\n",
      "1      Partial College                2.0\n",
      "2            Bachelors                3.0\n",
      "3      Partial College                2.0\n",
      "4      Partial College                2.0\n",
      "...                ...                ...\n",
      "18352  Graduate Degree                4.0\n",
      "18353        Bachelors                3.0\n",
      "18354  Partial College                2.0\n",
      "18355      High School                1.0\n",
      "18356  Graduate Degree                4.0\n",
      "\n",
      "[18357 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = pd.read_csv('combined_output.csv')\n",
    "\n",
    "education_order = [\n",
    "    'Partial High School',\n",
    "    'High School',\n",
    "    'Partial College',\n",
    "    'Bachelors',\n",
    "    'Graduate Degree'\n",
    "]\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[education_order])\n",
    "\n",
    "df['Education_encoded'] = encoder.fit_transform(df[['Education']])\n",
    "\n",
    "print(df[['Education', 'Education_encoded']])\n",
    "df.to_csv('label_encoded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da2ac775-9c67-4fe1-84f4-7aee48e3fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  City  StateProvinceName  Age  Occupation  Gender  \\\n",
      "0       21173   263                 27   37           0       1   \n",
      "1       13249   227                  5   52           0       1   \n",
      "2       29350   259                  6   39           0       0   \n",
      "3       13503   146                  8   47           4       1   \n",
      "4       22803   258                 30   49           4       1   \n",
      "\n",
      "   MaritalStatus  HomeOwnerFlag  NumberCarsOwned  NumberChildrenAtHome  \\\n",
      "0              0              1                3                     0   \n",
      "1              0              1                2                     1   \n",
      "2              1              0                3                     0   \n",
      "3              0              1                2                     1   \n",
      "4              1              1                1                     0   \n",
      "\n",
      "   YearlyIncome  BikeBuyer  AvgMonthSpend  Education  \n",
      "0         81916          1          50.97        3.0  \n",
      "1         81076          1          53.11        2.0  \n",
      "2         86387          1          54.08        3.0  \n",
      "3         61481          1          56.93        2.0  \n",
      "4         51804          1          55.41        2.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = pd.read_csv('label_encoded_data.csv')\n",
    "\n",
    "education_order = [\n",
    "    'Partial High School',\n",
    "    'High School',\n",
    "    'Partial College',\n",
    "    'Bachelors',\n",
    "    'Graduate Degree'\n",
    "]\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[education_order])\n",
    "\n",
    "df['Education_encoded'] = encoder.fit_transform(df[['Education']])\n",
    "\n",
    "df.drop('Education', axis=1, inplace=True)\n",
    "df.rename(columns={'Education_encoded': 'Education'}, inplace=True)\n",
    "\n",
    "df.to_csv('updated_combined_output.csv', index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ab89ec3-1674-4338-9466-c040b539cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4827d04-25fb-4279-93dc-936c5cea0f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Matching Coefficient: 0.3846\n",
      "Jaccard Similarity: 0.9091\n",
      "Cosine Similarity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "object1 = df.iloc[0][['City', 'StateProvinceName', 'Age', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag',\t'NumberCarsOwned', 'NumberChildrenAtHome', 'YearlyIncome', 'BikeBuyer',\t'AvgMonthSpend', 'Education']].values\n",
    "object2 = df.iloc[1][['City', 'StateProvinceName', 'Age', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag',\t'NumberCarsOwned', 'NumberChildrenAtHome', 'YearlyIncome', 'BikeBuyer',\t'AvgMonthSpend', 'Education']].values\n",
    "\n",
    "def simple_matching_coefficient(obj1, obj2):\n",
    "    matching_attributes = np.sum(obj1 == obj2)\n",
    "    total_attributes = len(obj1)\n",
    "    return matching_attributes / total_attributes\n",
    "\n",
    "def jaccard_similarity_binary(obj1, obj2):\n",
    "    return jaccard_score(obj1, obj2)\n",
    "\n",
    "def cosine_similarity_score(obj1, obj2):\n",
    "    return cosine_similarity([obj1], [obj2])[0][0]\n",
    "    \n",
    "object1_binary = (object1 > 0).astype(int)\n",
    "object2_binary = (object2 > 0).astype(int)\n",
    "\n",
    "simple_matching = simple_matching_coefficient(object1, object2)\n",
    "jaccard_sim = jaccard_similarity_binary(object1_binary, object2_binary)\n",
    "cosine_sim = cosine_similarity_score(object1, object2)\n",
    "\n",
    "print(f\"Simple Matching Coefficient: {simple_matching:.4f}\")\n",
    "print(f\"Jaccard Similarity: {jaccard_sim:.4f}\")\n",
    "print(f\"Cosine Similarity: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fca83d1-5ec5-4fbc-b048-2a47072bbabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Commute Distance and Yearly Income: 0.5301\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "df['AvgMonthSpend'] = pd.to_numeric(df['AvgMonthSpend'], errors='coerce')\n",
    "df['YearlyIncome'] = pd.to_numeric(df['YearlyIncome'], errors='coerce')\n",
    "\n",
    "correlation = df[['AvgMonthSpend', 'YearlyIncome']].corr().iloc[0, 1]\n",
    "\n",
    "print(f\"Correlation between Commute Distance and Yearly Income: {correlation:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b405773-f3d8-4f30-9ee5-61eaa899e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('label_encoded_data.csv')\n",
    "\n",
    "education_order = [\n",
    "    'Partial High School',\n",
    "    'High School',\n",
    "    'Partial College',\n",
    "    'Bachelors',\n",
    "    'Graduate Degree'\n",
    "]\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[education_order])\n",
    "\n",
    "df['Education_encoded'] = encoder.fit_transform(df[['Education']])\n",
    "\n",
    "df.drop('Education', axis=1, inplace=True)\n",
    "df.rename(columns={'Education_encoded': 'Education'}, inplace=True)\n",
    "\n",
    "df.to_csv('updated_combined_output.csv', index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551cfb2c-b8b6-4917-9bf5-643869782e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation values have been updated successfully.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('label_encoded_data.csv')\n",
    "\n",
    "occupation_mapping = {\n",
    "    0: 2,\n",
    "    1: 3,\n",
    "    2: 0,\n",
    "    3: 4,\n",
    "    4: 1\n",
    "}\n",
    "\n",
    "df['Occupation'] = df['Occupation'].map(occupation_mapping)\n",
    "\n",
    "df.to_csv('updated_file.csv', index=False)\n",
    "\n",
    "print(\"Occupation values have been updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e27d47-4bb2-478d-a37a-efc7374123cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation values have been successfully copied and replaced.\n"
     ]
    }
   ],
   "source": [
    "source_df = pd.read_csv('updated_file.csv')\n",
    "target_df = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "if 'Occupation' in source_df.columns and 'Occupation' in target_df.columns:\n",
    "    target_df['Occupation'] = source_df['Occupation']\n",
    "\n",
    "    target_df.to_csv('updated_combined_output.csv', index=False)\n",
    "    \n",
    "    print(\"Occupation values have been successfully copied and replaced.\")\n",
    "else:\n",
    "    print(\"The 'Occupation' column is missing in one of the files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "405dfd0f-ffff-4876-bb0a-14b931131b5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.5 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m state_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     67\u001b[0m k_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 69\u001b[0m knn_predict(city_code, state_code, k_value)\n",
      "Cell \u001b[1;32mIn[23], line 34\u001b[0m, in \u001b[0;36mknn_predict\u001b[1;34m(city_code, state_code, k)\u001b[0m\n\u001b[0;32m     31\u001b[0m features \u001b[38;5;241m=\u001b[39m filtered_data_city[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOccupation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYearlyIncome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvgMonthSpend\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     32\u001b[0m target \u001b[38;5;241m=\u001b[39m filtered_data_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 34\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     36\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     37\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.5 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "filtered_data = data[\n",
    "    (data['Age'] >= 18) & (data['Age'] <= 34) &\n",
    "    (data['Occupation'].isin([1, 2, 3])) &\n",
    "    (data['Gender'] == 1) &\n",
    "    (data['MaritalStatus'] == 1) &\n",
    "    (data['HomeOwnerFlag'] == 1) &\n",
    "    (data['NumberCarsOwned'] >= 0) & (data['NumberCarsOwned'] <= 2) &\n",
    "    (data['NumberChildrenAtHome'] == 0) &\n",
    "    (data['YearlyIncome'] >= 70000) &\n",
    "    (data['BikeBuyer'] == 0) &\n",
    "    (data['AvgMonthSpend'] < 80.00) &\n",
    "    (data['Education'].isin([2, 3, 4]))\n",
    "]\n",
    "\n",
    "def knn_predict(city_code, state_code, k):\n",
    "    if k < 500:\n",
    "        filtered_data_city = filtered_data[\n",
    "            (filtered_data['City'] == city_code) &\n",
    "            (filtered_data['StateProvinceName'] == state_code)\n",
    "        ]\n",
    "    else:\n",
    "        filtered_data_city = filtered_data\n",
    "\n",
    "    features = filtered_data_city[['Age', 'Occupation', 'YearlyIncome', 'AvgMonthSpend']]\n",
    "    target = filtered_data_city['CustomerID']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=50)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    output = pd.DataFrame({\n",
    "        'CustomerID': predictions,\n",
    "        'City': data.loc[data['CustomerID'].isin(predictions), 'City'],\n",
    "        'StateProvinceName': data.loc[data['CustomerID'].isin(predictions), 'StateProvinceName'],\n",
    "        'Age': data.loc[data['CustomerID'].isin(predictions), 'Age'],\n",
    "        'Occupation': data.loc[data['CustomerID'].isin(predictions), 'Occupation'],\n",
    "        'Gender': data.loc[data['CustomerID'].isin(predictions), 'Gender'],\n",
    "        'MaritalStatus': data.loc[data['CustomerID'].isin(predictions), 'MaritalStatus'],\n",
    "        'HomeOwnerFlag': data.loc[data['CustomerID'].isin(predictions), 'HomeOwnerFlag'],\n",
    "        'NumberCarsOwned': data.loc[data['CustomerID'].isin(predictions), 'NumberCarsOwned'],\n",
    "        'NumberChildrenAtHome': data.loc[data['CustomerID'].isin(predictions), 'NumberChildrenAtHome'],\n",
    "        'YearlyIncome': data.loc[data['CustomerID'].isin(predictions), 'YearlyIncome'],\n",
    "        'BikeBuyer': data.loc[data['CustomerID'].isin(predictions), 'BikeBuyer'],\n",
    "        'AvgMonthSpend': data.loc[data['CustomerID'].isin(predictions), 'AvgMonthSpend'],\n",
    "        'Education': data.loc[data['CustomerID'].isin(predictions), 'Education'],\n",
    "    })\n",
    "\n",
    "    output.to_csv('potential_bike_buyers.csv', index=False)\n",
    "    print(\"Output saved to 'potential_bike_buyers.csv'.\")\n",
    "\n",
    "city_code = 227\n",
    "state_code = 5\n",
    "k_value = 100\n",
    "\n",
    "knn_predict(city_code, state_code, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6bca1d3-b6a7-414c-8fac-c553297bbbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough data available after filtering with the given conditions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "# Filter the data according to the conditions provided\n",
    "filtered_data = data[\n",
    "    (data['Age'] >= 18) & (data['Age'] <= 45) &\n",
    "    (data['Occupation'].isin([1, 2, 3])) &\n",
    "    (data['Gender'] == 1) &\n",
    "    (data['MaritalStatus'] == 1) &\n",
    "    (data['HomeOwnerFlag'] == 1) &\n",
    "    (data['NumberCarsOwned'] >= 0) & (data['NumberCarsOwned'] <= 2) &\n",
    "    (data['NumberChildrenAtHome'] == 0) &\n",
    "    (data['YearlyIncome'] >= 50000) &\n",
    "    (data['BikeBuyer'] == 0) &\n",
    "    (data['AvgMonthSpend'] < 80) &\n",
    "    (data['Education'].isin([3, 4]))\n",
    "]\n",
    "\n",
    "def knn_predict(city_code, state_code, k):\n",
    "    if k < 500:\n",
    "        filtered_data_city = filtered_data[\n",
    "            (filtered_data['City'] == city_code) &\n",
    "            (filtered_data['StateProvinceName'] == state_code)\n",
    "        ]\n",
    "    else:\n",
    "        filtered_data_city = filtered_data\n",
    "\n",
    "    if len(filtered_data_city) < 2:\n",
    "        print(\"Not enough data available after filtering with the given conditions.\")\n",
    "        return\n",
    "    \n",
    "    features = filtered_data_city[['Age', 'Occupation', 'YearlyIncome', 'AvgMonthSpend']]\n",
    "    target = filtered_data_city['CustomerID']\n",
    "    \n",
    "    test_size = 0.5 if len(filtered_data_city) > 10 else 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=50)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    output = pd.DataFrame({\n",
    "        'CustomerID': predictions,\n",
    "        'City': data.loc[data['CustomerID'].isin(predictions), 'City'],\n",
    "        'StateProvinceName': data.loc[data['CustomerID'].isin(predictions), 'StateProvinceName'],\n",
    "        'Age': data.loc[data['CustomerID'].isin(predictions), 'Age'],\n",
    "        'Occupation': data.loc[data['CustomerID'].isin(predictions), 'Occupation'],\n",
    "        'Gender': data.loc[data['CustomerID'].isin(predictions), 'Gender'],\n",
    "        'MaritalStatus': data.loc[data['CustomerID'].isin(predictions), 'MaritalStatus'],\n",
    "        'HomeOwnerFlag': data.loc[data['CustomerID'].isin(predictions), 'HomeOwnerFlag'],\n",
    "        'NumberCarsOwned': data.loc[data['CustomerID'].isin(predictions), 'NumberCarsOwned'],\n",
    "        'NumberChildrenAtHome': data.loc[data['CustomerID'].isin(predictions), 'NumberChildrenAtHome'],\n",
    "        'YearlyIncome': data.loc[data['CustomerID'].isin(predictions), 'YearlyIncome'],\n",
    "        'BikeBuyer': data.loc[data['CustomerID'].isin(predictions), 'BikeBuyer'],\n",
    "        'AvgMonthSpend': data.loc[data['CustomerID'].isin(predictions), 'AvgMonthSpend'],\n",
    "        'Education': data.loc[data['CustomerID'].isin(predictions), 'Education'],\n",
    "    })\n",
    "\n",
    "    output.to_csv('potential_bike_buyers.csv', index=False)\n",
    "    print(\"Output saved to 'potential_bike_buyers.csv'.\")\n",
    "\n",
    "city_code = 183\n",
    "state_code = 48\n",
    "k_value = 10\n",
    "\n",
    "knn_predict(city_code, state_code, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f19321bf-52e8-4154-af07-5ac6a8ce79e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 5, n_samples_fit = 4, n_samples = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m state_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     68\u001b[0m k_value \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m---> 70\u001b[0m knn_predict(state_code, k_value)\n",
      "Cell \u001b[1;32mIn[61], line 45\u001b[0m, in \u001b[0;36mknn_predict\u001b[1;34m(state_code, k)\u001b[0m\n\u001b[0;32m     42\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m     43\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 45\u001b[0m predictions \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     47\u001b[0m output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions,\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m: data\u001b[38;5;241m.\u001b[39mloc[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(predictions), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation\u001b[39m\u001b[38;5;124m'\u001b[39m: data\u001b[38;5;241m.\u001b[39mloc[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(predictions), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     62\u001b[0m })\n\u001b[0;32m     64\u001b[0m output\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotential_bike_buyers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:835\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 835\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    842\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 5, n_samples_fit = 4, n_samples = 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "def knn_predict(state_code, k):\n",
    "    filtered_data = data[\n",
    "        (data['Age'] >= 18) & (data['Age'] <= 45) &  \n",
    "        (data['Occupation'].isin([0, 1, 2, 3, 4])) &    \n",
    "        (data['Gender'] == 1) &\n",
    "        (data['MaritalStatus'] == 1) &\n",
    "        (data['HomeOwnerFlag'] == 1) &\n",
    "        (data['NumberCarsOwned'] >= 0) & (data['NumberCarsOwned'] <= 2) &\n",
    "        (data['NumberChildrenAtHome'] <= 1) &       \n",
    "        (data['YearlyIncome'] >= 50000) &            \n",
    "        (data['BikeBuyer'] == 0) &\n",
    "        (data['AvgMonthSpend'] > 40.00) &              \n",
    "        (data['Education'].isin([3, 4]))\n",
    "    ]\n",
    "\n",
    "    filtered_data_state = filtered_data[\n",
    "        filtered_data['StateProvinceName'] == state_code\n",
    "    ]\n",
    "\n",
    "    if len(filtered_data_state) < 2:\n",
    "        print(f\"Not enough data available after filtering. Found {len(filtered_data_state)} records.\")\n",
    "        return\n",
    "    \n",
    "    # Select features and target\n",
    "    features = filtered_data_state[['Age', 'Occupation', 'YearlyIncome', 'AvgMonthSpend']]\n",
    "    target = filtered_data_state['CustomerID']\n",
    "    \n",
    "    test_size = 0.5 if len(filtered_data_state) > 10 else 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=50)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "  \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    output = pd.DataFrame({\n",
    "        'CustomerID': predictions,\n",
    "        'City': data.loc[data['CustomerID'].isin(predictions), 'City'],\n",
    "        'StateProvinceName': data.loc[data['CustomerID'].isin(predictions), 'StateProvinceName'],\n",
    "        'Age': data.loc[data['CustomerID'].isin(predictions), 'Age'],\n",
    "        'Occupation': data.loc[data['CustomerID'].isin(predictions), 'Occupation'],\n",
    "        'Gender': data.loc[data['CustomerID'].isin(predictions), 'Gender'],\n",
    "        'MaritalStatus': data.loc[data['CustomerID'].isin(predictions), 'MaritalStatus'],\n",
    "        'HomeOwnerFlag': data.loc[data['CustomerID'].isin(predictions), 'HomeOwnerFlag'],\n",
    "        'NumberCarsOwned': data.loc[data['CustomerID'].isin(predictions), 'NumberCarsOwned'],\n",
    "        'NumberChildrenAtHome': data.loc[data['CustomerID'].isin(predictions), 'NumberChildrenAtHome'],\n",
    "        'YearlyIncome': data.loc[data['CustomerID'].isin(predictions), 'YearlyIncome'],\n",
    "        'BikeBuyer': data.loc[data['CustomerID'].isin(predictions), 'BikeBuyer'],\n",
    "        'AvgMonthSpend': data.loc[data['CustomerID'].isin(predictions), 'AvgMonthSpend'],\n",
    "        'Education': data.loc[data['CustomerID'].isin(predictions), 'Education'],\n",
    "    })\n",
    "\n",
    "    output.to_csv('potential_bike_buyers.csv', index=False)\n",
    "    print(\"Output saved to 'potential_bike_buyers.csv'.\")\n",
    "\n",
    "state_code = 5\n",
    "k_value =5\n",
    "\n",
    "knn_predict(state_code, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "edd5b2a5-7adc-4529-85db-a6d086fabed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough data available after filtering. Found 0 records.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "def knn_predict(state_code, k):\n",
    "    \n",
    "    filtered_data = data[\n",
    "        (data['Age'] >= 18) & (data['Age'] <= 45) & \n",
    "        (data['Occupation'].isin([1, 2, 3, 4])) &    \n",
    "        (data['Gender'] == 1) &\n",
    "        (data['MaritalStatus'] == 1) &\n",
    "        (data['HomeOwnerFlag'] == 1) &\n",
    "        (data['NumberCarsOwned'] >= 0) & (data['NumberCarsOwned'] <= 2) &\n",
    "        (data['NumberChildrenAtHome'] <= 1) &       \n",
    "        (data['YearlyIncome'] >= 40000) &           \n",
    "        (data['BikeBuyer'] <= 1) &\n",
    "        (data['AvgMonthSpend'] < 100) &             \n",
    "        (data['Education'].isin([2, 3, 4]))\n",
    "    ]\n",
    "\n",
    "    filtered_data_state = filtered_data[\n",
    "        filtered_data['StateProvinceName'] == state_code\n",
    "    ]\n",
    "\n",
    "    if len(filtered_data_state) < 2:\n",
    "        print(f\"Not enough data available after filtering. Found {len(filtered_data_state)} records.\")\n",
    "        return\n",
    "    \n",
    "   \n",
    "    features = filtered_data_state[['Age', 'Occupation', 'YearlyIncome', 'AvgMonthSpend']]\n",
    "    target = filtered_data_state['CustomerID']\n",
    "    \n",
    " \n",
    "    test_size = 0.5 if len(filtered_data_state) > 10 else 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=50)\n",
    "\n",
    "   \n",
    "    if k > len(X_train):\n",
    "        print(f\"Reducing k from {k} to {len(X_train)} due to insufficient data.\")\n",
    "        k = len(X_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "  \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "  \n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    output = pd.DataFrame({\n",
    "        'CustomerID': predictions,\n",
    "        'City': data.loc[data['CustomerID'].isin(predictions), 'City'],\n",
    "        'StateProvinceName': data.loc[data['CustomerID'].isin(predictions), 'StateProvinceName'],\n",
    "        'Age': data.loc[data['CustomerID'].isin(predictions), 'Age'],\n",
    "        'Occupation': data.loc[data['CustomerID'].isin(predictions), 'Occupation'],\n",
    "        'Gender': data.loc[data['CustomerID'].isin(predictions), 'Gender'],\n",
    "        'MaritalStatus': data.loc[data['CustomerID'].isin(predictions), 'MaritalStatus'],\n",
    "        'HomeOwnerFlag': data.loc[data['CustomerID'].isin(predictions), 'HomeOwnerFlag'],\n",
    "        'NumberCarsOwned': data.loc[data['CustomerID'].isin(predictions), 'NumberCarsOwned'],\n",
    "        'NumberChildrenAtHome': data.loc[data['CustomerID'].isin(predictions), 'NumberChildrenAtHome'],\n",
    "        'YearlyIncome': data.loc[data['CustomerID'].isin(predictions), 'YearlyIncome'],\n",
    "        'BikeBuyer': data.loc[data['CustomerID'].isin(predictions), 'BikeBuyer'],\n",
    "        'AvgMonthSpend': data.loc[data['CustomerID'].isin(predictions), 'AvgMonthSpend'],\n",
    "        'Education': data.loc[data['CustomerID'].isin(predictions), 'Education'],\n",
    "    })\n",
    "\n",
    "    output.to_csv('potential_bike_buyers.csv', index=False)\n",
    "    print(\"Output saved to 'potential_bike_buyers.csv'.\")\n",
    "\n",
    "state_code = 10\n",
    "k_value = 19\n",
    "\n",
    "knn_predict(state_code, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "772bc18e-78f1-40a0-a7b9-d3a85527518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough data available after filtering. Found 0 records.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_combined_output.csv')\n",
    "\n",
    "def knn_predict(state_code, k):\n",
    "    # Filter based on the given StateProvinceName code\n",
    "    filtered_data_state = data[data['StateProvinceName'] == state_code]\n",
    "\n",
    "    # Check if any data is available after filtering\n",
    "    if filtered_data_state.empty:\n",
    "        print(f\"No data available for StateProvinceName = {state_code}.\")\n",
    "        return\n",
    "    \n",
    "    # Additional filtering criteria\n",
    "    filtered_data_state = filtered_data_state[\n",
    "        (filtered_data_state['Age'] >= 18) & (filtered_data_state['Age'] <= 40) &  # Age range\n",
    "        (filtered_data_state['Occupation'].isin([1, 2, 3, 4])) &    # Occupation categories\n",
    "        (filtered_data_state['Gender'] == 1) &\n",
    "        (filtered_data_state['MaritalStatus'] == 1) &\n",
    "        (filtered_data_state['HomeOwnerFlag'] == 1) &\n",
    "        (filtered_data_state['NumberCarsOwned'] >= 0) & (filtered_data_state['NumberCarsOwned'] <= 2) &\n",
    "        (filtered_data_state['NumberChildrenAtHome'] <= 1) &        # Number of children\n",
    "        (filtered_data_state['YearlyIncome'] >= 90000) &            # Income threshold\n",
    "        (filtered_data_state['BikeBuyer'] == 0) &\n",
    "        (filtered_data_state['AvgMonthSpend'] < 100) &              # Monthly spending limit\n",
    "        (filtered_data_state['Education'].isin([3, 4]))\n",
    "    ]\n",
    "\n",
    "    # Check if the filtered dataset is empty or too small for splitting\n",
    "    if len(filtered_data_state) < 2:\n",
    "        print(f\"Not enough data available after filtering. Found {len(filtered_data_state)} records.\")\n",
    "        return\n",
    "    \n",
    "    # Select features and target\n",
    "    features = filtered_data_state[['Age', 'Occupation', 'YearlyIncome', 'AvgMonthSpend']]\n",
    "    target = filtered_data_state['CustomerID']\n",
    "    \n",
    "    # Train-test split with a smaller test size if the dataset is small\n",
    "    test_size = 0.5 if len(filtered_data_state) > 10 else 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=50)\n",
    "\n",
    "    # Adjust k if it's greater than the number of samples in the training set\n",
    "    if k > len(X_train):\n",
    "        print(f\"Reducing k from {k} to {len(X_train)} due to insufficient data.\")\n",
    "        k = len(X_train)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # KNN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Save the output\n",
    "    output = pd.DataFrame({\n",
    "        'CustomerID': predictions,\n",
    "        'City': data.loc[data['CustomerID'].isin(predictions), 'City'],\n",
    "        'StateProvinceName': data.loc[data['CustomerID'].isin(predictions), 'StateProvinceName'],\n",
    "        'Age': data.loc[data['CustomerID'].isin(predictions), 'Age'],\n",
    "        'Occupation': data.loc[data['CustomerID'].isin(predictions), 'Occupation'],\n",
    "        'Gender': data.loc[data['CustomerID'].isin(predictions), 'Gender'],\n",
    "        'MaritalStatus': data.loc[data['CustomerID'].isin(predictions), 'MaritalStatus'],\n",
    "        'HomeOwnerFlag': data.loc[data['CustomerID'].isin(predictions), 'HomeOwnerFlag'],\n",
    "        'NumberCarsOwned': data.loc[data['CustomerID'].isin(predictions), 'NumberCarsOwned'],\n",
    "        'NumberChildrenAtHome': data.loc[data['CustomerID'].isin(predictions), 'NumberChildrenAtHome'],\n",
    "        'YearlyIncome': data.loc[data['CustomerID'].isin(predictions), 'YearlyIncome'],\n",
    "        'BikeBuyer': data.loc[data['CustomerID'].isin(predictions), 'BikeBuyer'],\n",
    "        'AvgMonthSpend': data.loc[data['CustomerID'].isin(predictions), 'AvgMonthSpend'],\n",
    "        'Education': data.loc[data['CustomerID'].isin(predictions), 'Education'],\n",
    "    })\n",
    "\n",
    "    output.to_csv('potential_bike_buyers.csv', index=False)\n",
    "    print(\"Output saved to 'potential_bike_buyers.csv'.\")\n",
    "\n",
    "# Example usage\n",
    "state_code = 10  # Replace with your actual state code value\n",
    "k_value = 50\n",
    "\n",
    "knn_predict(state_code, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1651c1f-9acc-4a6e-9188-84cc5f7b3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('customer_data.csv')\n",
    "\n",
    "def alternative_predict(state_code, algorithm='decision_tree', k=None):\n",
    "    # Filter based on the given StateProvinceName code\n",
    "    filtered_data_state = data[data['StateProvinceName'] == state_code]\n",
    "\n",
    "    # Check if any data is available after filtering\n",
    "    if filtered_data_state.empty:\n",
    "        print(f\"No data available for StateProvinceName = {state_code}.\")\n",
    "        return\n",
    "    \n",
    "    # Apply further filtering based on other criteria\n",
    "    filtered_data_state = filtered_data_state[\n",
    "        (filtered_data_state['Age'] >= 18) & (filtered_data_state['Age'] <= 40) &  # Age range\n",
    "        (filtered_data_state['Occupation'].isin([1, 2, 3, 4])) &    # Occupation categories\n",
    "        (filtered_data_state['Gender'] == 1) &\n",
    "        (filtered_data_state['MaritalStatus'] == 1) &\n",
    "        (filtered_data_state['HomeOwnerFlag'] == 1) &\n",
    "        (filtered_data_state['NumberCarsOwned'] >= 0) & (filtered_data_state['NumberCarsOwned'] <= 2) &\n",
    "        (filtered_data_state['NumberChildrenAtHome'] <= 1) &        # Number of children\n",
    "        (filtered_data_state['YearlyIncome'] >= 90000) &            # Income threshold\n",
    "        (filtered_data_state['BikeBuyer'] == 0) &\n",
    "        (filtered_data_state['AvgMonthSpend'] < 100) &              # Monthly spending limit\n",
    "        (filtered_data_state['Education'].isin([3, 4]))\n",
    "    ]\n",
    "\n",
    "    # Check if the filtered dataset is empty or too small for splitting\n",
    "    if len(filtered_data_state) == 0:\n",
    "        print(f\"Not enough data available after filtering. Found {len(filtered_data_state)} records.\")\n",
    "        return\n",
    "    \n",
    "    # Select features and target\n",
    "    features = filtered_data_state[['Age', 'Occupation', 'YearlyIncome', 'AvgMonthSpend']]\n",
    "    target = filtered_data_state['CustomerID']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=50)\n",
    "\n",
    "    # Standardize features if needed\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Select the algorithm\n",
    "    if algorithm == 'decision_tree':\n",
    "        model = DecisionTreeClassifier(random_state=50)\n",
    "    elif algorithm == 'random_forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "    elif algorithm == 'logistic_regression':\n",
    "        model = LogisticRegression(random_state=50)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid algorithm specified. Choose 'decision_tree', 'random_forest', or 'logistic_regression'.\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Save the output\n",
    "    output = pd.DataFrame({\n",
    "        'CustomerID': predictions,\n",
    "        'City': data.loc[data['CustomerID'].isin(predictions), 'City'],\n",
    "        'StateProvinceName': data.loc[data['CustomerID'].isin(predictions), 'StateProvinceName'],\n",
    "        'Age': data.loc[data['CustomerID'].isin(predictions), 'Age'],\n",
    "        'Occupation': data.loc[data['CustomerID'].isin(predictions), 'Occupation'],\n",
    "        'Gender': data.loc[data['CustomerID'].isin(predictions), 'Gender'],\n",
    "        'MaritalStatus': data.loc[data['CustomerID'].isin(predictions), 'MaritalStatus'],\n",
    "        'HomeOwnerFlag': data.loc[data['CustomerID'].isin(predictions), 'HomeOwnerFlag'],\n",
    "        'NumberCarsOwned': data.loc[data['CustomerID'].isin(predictions), 'NumberCarsOwned'],\n",
    "        'NumberChildrenAtHome': data.loc[data['CustomerID'].isin(predictions), 'NumberChildrenAtHome'],\n",
    "        'YearlyIncome': data.loc[data['CustomerID'].isin(predictions), 'YearlyIncome'],\n",
    "        'BikeBuyer': data.loc[data['CustomerID'].isin(predictions), 'BikeBuyer'],\n",
    "        'AvgMonthSpend': data.loc[data['CustomerID'].isin(predictions), 'AvgMonthSpend'],\n",
    "        'Education': data.loc[data['CustomerID'].isin(predictions), 'Education'],\n",
    "    })\n",
    "\n",
    "    output.to_csv('potential_bike_buyers.csv', index=False)\n",
    "    print(f\"Output saved to 'potential_bike_buyers.csv' using {algorithm}.\")\n",
    "\n",
    "# Example usage\n",
    "state_code = 'your_state_code'  # Replace with your actual state code value\n",
    "algorithm_choice = 'decision_tree'  # Options: 'decision_tree', 'random_forest', 'logistic_regression'\n",
    "k_value = 50  # Optional for KNN, but can be ignored here\n",
    "\n",
    "alternative_predict(state_code, algorithm=algorithm_choice, k=k_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
